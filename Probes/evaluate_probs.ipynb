{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to evaluate the probs of the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fever\n",
      "AUROC for minimum probability: 0.6492\n",
      "AUROC for token weighted score: 0.6076\n",
      "AUROC for entropy: 0.6384\n",
      "hover\n",
      "AUROC for minimum probability: 0.6893\n",
      "AUROC for token weighted score: 0.6493\n",
      "AUROC for entropy: 0.6735\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "datasets = [\"fever\", \"hover\"]\n",
    "model_name = \"llama\"\n",
    "df_metrics = pd.DataFrame()\n",
    "\n",
    "for dataset in datasets:\n",
    "    df_sentence_test = pd.read_pickle(f\"probs_test_{model_name}/probs_sentence_{dataset}_with_token_importance.pkl\")\n",
    "\n",
    "    def calc_min_prob(probs):\n",
    "        \"\"\"Calculate the minimum probability from concat_probs.\"\"\"\n",
    "        return min(probs)\n",
    "\n",
    "\n",
    "    def calc_token_importance(token_importance, probs, pe):\n",
    "        \"\"\"Calculate tokensar using token importance and probabilities.\"\"\"\n",
    "        log_probs = [-math.log(prob) * prob for prob in probs]\n",
    "        weighted_score = (token_importance / token_importance.sum()) * torch.tensor(log_probs)\n",
    "        return weighted_score.sum().item()\n",
    "\n",
    "    def calc_entropy(pe):\n",
    "        \"\"\"Calculate the average entropy from concat_probs.\"\"\"\n",
    "        return sum(pe) / len(pe)\n",
    "\n",
    "\n",
    "    def process_row(row):\n",
    "        concat_probs = row['concat_probs_sentence']\n",
    "\n",
    "        # llama\n",
    "        if model_name == \"llama\":\n",
    "            probs = [probs[2] for probs in concat_probs]\n",
    "            probs = [item for sublist in probs for item in sublist]\n",
    "            pe = [probs[3] for probs in concat_probs]\n",
    "            pe = [item for sublist in pe for item in sublist]\n",
    "\n",
    "        # phi \n",
    "        elif model_name == \"phi\":\n",
    "            probs = [probs[1] for probs in concat_probs]\n",
    "            pe = [probs[2] for probs in concat_probs]\n",
    "\n",
    "        token_importance = torch.tensor(row['token_importance'])\n",
    "        label = row['label_sentence']\n",
    "\n",
    "        if not probs:\n",
    "            return None\n",
    "        else:\n",
    "            min_prob = calc_min_prob(probs)\n",
    "            entropy = calc_entropy(pe)\n",
    "            weighted_score = calc_token_importance(token_importance, probs, pe)\n",
    "\n",
    "        return pd.Series({\n",
    "            \"label_sentence\": label,\n",
    "            \"min_prob\": min_prob,\n",
    "            \"token_weighted_score\": weighted_score,\n",
    "            \"entropy\": entropy\n",
    "        })\n",
    "\n",
    "    def process_dataframe(df):\n",
    "        return df.apply(process_row, axis=1).dropna()\n",
    "\n",
    "    df_results = df_sentence_test.copy()\n",
    "    df_results = process_dataframe(df_results)\n",
    "\n",
    "    def calculate_auroc(df, col_name, inverse=False):\n",
    "        if inverse:\n",
    "            labels = 1 - df[\"label_sentence\"]\n",
    "        else:\n",
    "            labels = df[\"label_sentence\"]\n",
    "        prob_scores = df[col_name]\n",
    "        auroc = roc_auc_score(labels, prob_scores)\n",
    "        return auroc\n",
    "    \n",
    "\n",
    "    auroc_min_prob = calculate_auroc(df_results, \"min_prob\")\n",
    "    auroc_entropy = calculate_auroc(df_results, \"entropy\", inverse=True)\n",
    "    auroc_token_weighted_score = calculate_auroc(df_results, \"token_weighted_score\", inverse=True)\n",
    "\n",
    "    new_metrics_df = pd.DataFrame({\n",
    "        \"auroc\": [auroc_min_prob, auroc_entropy, auroc_token_weighted_score],\n",
    "        \"metric\": [\"min_prob\", \"entropy\", \"token_weighted_score\"],\n",
    "        \"dataset\": [dataset] * 3\n",
    "    })\n",
    "\n",
    "    df_metrics = pd.concat([df_metrics, new_metrics_df], ignore_index=True)\n",
    "\n",
    "    # Results\n",
    "    print(f\"AUROC for minimum probability: {auroc_min_prob:.4f}\")\n",
    "    print(f\"AUROC for token weighted score: {auroc_token_weighted_score:.4f}\")\n",
    "    print(f\"AUROC for entropy: {auroc_entropy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
