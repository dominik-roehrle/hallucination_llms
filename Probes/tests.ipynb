{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to evaluate the quality of the mini-facts from the evidence with BART-large-MNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "bart_model_path = \"D:\\huggingface\\huggingface\\hub\\models--facebook--bart-large-mnli\\snapshots\\d7645e127eaf1aefc7862fd59a17a5aa8558b8ce\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Loading BART model...\")\n",
    "bart_model = AutoModelForSequenceClassification.from_pretrained(bart_model_path, local_files_only=True)\n",
    "bart_tokenizer = AutoTokenizer.from_pretrained(bart_model_path, local_files_only=True)\n",
    "bart_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_source_to_fit_with_hypothesis(source, hypothesis, bart_tokenizer, max_length=1024):\n",
    "    \"\"\"Splits the source into chunks so that each chunk, when combined with the hypothesis, fits within the token limit.\"\"\"\n",
    "    original_max_length = bart_tokenizer.model_max_length\n",
    "    bart_tokenizer.model_max_length = int(1e12)  \n",
    "    hypothesis_tokens = bart_tokenizer.encode(hypothesis, add_special_tokens=False)\n",
    "    hypothesis_length = len(hypothesis_tokens)\n",
    "    num_special_tokens = bart_tokenizer.num_special_tokens_to_add(pair=True)\n",
    "    max_source_length = max_length - hypothesis_length - num_special_tokens\n",
    "    if max_source_length <= 0:\n",
    "        bart_tokenizer.model_max_length = original_max_length\n",
    "        raise ValueError(\"The hypothesis is too long to fit within the max_length limit.\")\n",
    "    source_tokens = bart_tokenizer.encode(source, add_special_tokens=False)\n",
    "    bart_tokenizer.model_max_length = original_max_length\n",
    "    token_chunks = [source_tokens[i:i+max_source_length] for i in range(0, len(source_tokens), max_source_length)]\n",
    "    text_chunks = [bart_tokenizer.decode(chunk, skip_special_tokens=True) for chunk in token_chunks]\n",
    "    return text_chunks\n",
    "    \n",
    "def call_bart_model(source, statement):\n",
    "    source_chunks = split_source_to_fit_with_hypothesis(source, statement, bart_tokenizer, max_length=1024)\n",
    "    entailment_probs = []\n",
    "    pred_labels = []\n",
    "    for idx, chunk in enumerate(source_chunks):\n",
    "        inputs = bart_tokenizer(\n",
    "            chunk,\n",
    "            statement,\n",
    "            return_tensors='pt',\n",
    "            truncation=True,\n",
    "            max_length=1024,\n",
    "            add_special_tokens=True\n",
    "        )\n",
    "        input_length = inputs['input_ids'].shape[1]\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = bart_model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            dominating_class = probs.argmax(dim=1).item()\n",
    "\n",
    "        class_names = [\"Contradiction\", \"Neutral\", \"Entailment\"]\n",
    "        prob_entailment = probs[:, 2].item()\n",
    "        entailment_probs.append(prob_entailment)\n",
    "        pred_labels.append(class_names[dominating_class])\n",
    "\n",
    "    filtered_labels = [label for label in pred_labels if label != \"Neutral\"]\n",
    "    if filtered_labels:\n",
    "        final_label = max(set(filtered_labels), key=pred_labels.count)\n",
    "    else:\n",
    "        final_label = max(set(pred_labels), key=pred_labels.count)\n",
    "    return final_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "samples = 1000\n",
    "df = pd.read_pickle(\"datasets_fever/mini_fact_fever.pkl\").iloc[:samples]\n",
    "\n",
    "counter_entailment = 0\n",
    "grouped_df = df.groupby(\"gen_evidence\")\n",
    "\n",
    "for name, group in grouped_df:\n",
    "    mini_facts = group[\"output_mini_fact\"].tolist()\n",
    "    gen_evidence = group[\"gen_evidence\"].iloc[0]\n",
    "    for mini_fact in mini_facts:\n",
    "        label = call_bart_model(gen_evidence, mini_fact)\n",
    "        if label == \"Entailment\":\n",
    "            counter_entailment += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_entailment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests Probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "dataset = \"hover\"\n",
    "\n",
    "df1 = pd.read_pickle(f\"probs_test_llama/df_new_{dataset}_probs_sentence.pkl\")\n",
    "df2 = pd.read_pickle(f\"processed_datasets_with_bart_{dataset}_layer-1/sentence_{dataset}_test_unbalanced.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen_evidence in df1[\"output_sentence\"].tolist():\n",
    "    if gen_evidence not in df2[\"output_sentence\"].tolist():\n",
    "        print(gen_evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen_evidence in df2[\"output_sentence\"].tolist():\n",
    "    if gen_evidence not in df1[\"output_sentence\"].tolist():\n",
    "        print(gen_evidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests Mini Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "dataset = \"fever\"\n",
    "\n",
    "df_train = pd.read_pickle(f\"processed_datasets_with_bart_{dataset}_layer-8/mini_fact_{dataset}_train.pkl\")\n",
    "print(len(df_train))\n",
    "df_dev = pd.read_pickle(f\"processed_datasets_with_bart_{dataset}_layer-8/mini_fact_{dataset}_dev.pkl\")\n",
    "print(len(df_dev))\n",
    "df_test = pd.read_pickle(f\"processed_datasets_with_bart_{dataset}_layer-8/mini_fact_{dataset}_test_unbalanced.pkl\")\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(f\"processed_datasets_with_bart_{dataset}_layer-1/mini_fact_{dataset}_train.pkl\")\n",
    "df_test = pd.read_pickle(f\"processed_datasets_with_bart_{dataset}_layer-1/mini_fact_{dataset}_test_unbalanced.pkl\")\n",
    "\n",
    "\n",
    "all_docs1 = [item for sublist in df_train['docs'] for item in sublist]\n",
    "all_docs2 = [item for sublist in df_test['docs'] for item in sublist]\n",
    "\n",
    "mini_facts_train = df_train[\"output_mini_fact\"].tolist() \n",
    "mini_facts_test = df_test[\"output_mini_fact\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mini_fact in mini_facts_train:\n",
    "    if mini_fact in mini_facts_test:\n",
    "        print(mini_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mini_fact in mini_facts_test:\n",
    "    if mini_fact in mini_facts_train:\n",
    "        print(mini_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_docs1 = set(all_docs1)\n",
    "set_docs2 = set(all_docs2)\n",
    "\n",
    "# Check if there's any overlap\n",
    "common_docs = set_docs1.intersection(set_docs2)\n",
    "\n",
    "# Print the result\n",
    "if not common_docs:\n",
    "    print(\"No common documents found between df1 and df2.\")\n",
    "else:\n",
    "    print(\"Common documents found:\", common_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = \"fever\"\n",
    "\n",
    "df = pd.read_pickle(\"datasets_hover_llama/gen_evidence_hover.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = \"fever\"\n",
    "\n",
    "df_train = pd.read_pickle(f\"processed_datasets_llama_{dataset}_layer-1/sentence_{dataset}_train.pkl\")\n",
    "df_test = pd.read_pickle(f\"processed_datasets_llama_{dataset}_layer-1/sentence_{dataset}_test_unbalanced.pkl\")\n",
    "print(len(df_train))\n",
    "\n",
    "\n",
    "all_docs1 = [item for sublist in df_train['docs'] for item in sublist]\n",
    "all_docs2 = [item for sublist in df_test['docs'] for item in sublist]\n",
    "\n",
    "sentence_train = df_train[\"output_sentence\"].tolist() \n",
    "sentence_test = df_test[\"output_sentence\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentence_train:\n",
    "    if sentence in sentence_test:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in sentence_test:\n",
    "    if sentence in sentence_train:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_docs1 = set(all_docs1)\n",
    "set_docs2 = set(all_docs2)\n",
    "\n",
    "# Check if there's any overlap\n",
    "common_docs = set_docs1.intersection(set_docs2)\n",
    "\n",
    "# Print the result\n",
    "if not common_docs:\n",
    "    print(\"No common documents found between df1 and df2.\")\n",
    "else:\n",
    "    print(\"Common documents found:\", common_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mini Facts - Sentence Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_sentence = pd.read_pickle(f\"processed_datasets_with_bart_{dataset}_layer-1/sentence_{dataset}_test_unbalanced.pkl\")\n",
    "df_test_mini_fact = pd.read_pickle(f\"processed_datasets_with_bart_{dataset}_layer-1/mini_fact_{dataset}_test_unbalanced.pkl\")\n",
    "\n",
    "\n",
    "def balance_dataframe(df, label_name):\n",
    "        df_label_1 = df[df[str(label_name)] == 1]\n",
    "        df_label_0 = df[df[str(label_name)] == 0]\n",
    "        min_class_count = min(len(df_label_1), len(df_label_0))\n",
    "        df_label_1_downsampled = df_label_1.sample(min_class_count, random_state=42)\n",
    "        df_label_0_downsampled = df_label_0.sample(min_class_count, random_state=42)\n",
    "        balanced_df = pd.concat([df_label_1_downsampled, df_label_0_downsampled])\n",
    "        return balanced_df.reset_index(drop=True)\n",
    "\n",
    "df_test_sentence = balance_dataframe(df_test_sentence, 'label_sentence')\n",
    "df_test_mini_fact = df_test_mini_fact[df_test_mini_fact['gen_sentence'].isin(df_test_sentence['output_sentence'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen_s in df_test_mini_fact['gen_sentence'].tolist():\n",
    "    if gen_s not in df_test_sentence['output_sentence'].tolist():\n",
    "        print(gen_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen_s in df_test_sentence['output_sentence'].tolist():\n",
    "    if gen_s not in df_test_mini_fact['gen_sentence'].tolist():\n",
    "        print(gen_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manual Check that all mini facts remain in sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped = df_test_mini_fact.groupby(\"gen_sentence\")\n",
    "\n",
    "\n",
    "for name, group in df_grouped:\n",
    "    gen_sentence = group[\"gen_sentence\"].iloc[0]\n",
    "    print(gen_sentence)\n",
    "    mini_facts = group[\"output_mini_fact\"].tolist()\n",
    "    print(mini_facts)\n",
    "    print(\"###\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = \"hover\"\n",
    "\n",
    "df1 = pd.read_pickle(f\"probs_test_phi/probs_sentence_{dataset}.pkl\")\n",
    "df2 = pd.read_pickle(f\"processed_datasets_phi/sentence_{dataset}_layer-1_test_unbalanced.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen_evidence in df1[\"output_sentence\"].tolist():\n",
    "    if gen_evidence not in df2[\"output_sentence\"].tolist():\n",
    "        print(gen_evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gen_evidence in df2[\"output_sentence\"].tolist():\n",
    "    if gen_evidence not in df1[\"output_sentence\"].tolist():\n",
    "        print(gen_evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_pickle(f\"processed_datasets_llama_{dataset}_layer-1/mini_fact_{dataset}_train.pkl\")\n",
    "df_test = pd.read_pickle(f\"processed_datasets_phi_llama/mini_fact_{dataset}_layer-1_test_unbalanced.pkl\")\n",
    "\n",
    "\n",
    "all_docs1 = [item for sublist in df_train['docs'] for item in sublist]\n",
    "all_docs2 = [item for sublist in df_test['docs'] for item in sublist]\n",
    "\n",
    "mini_facts_train = df_train[\"output_mini_fact\"].tolist() \n",
    "mini_facts_test = df_test[\"output_mini_fact\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mini_fact in mini_facts_train:\n",
    "    if mini_fact in mini_facts_test:\n",
    "        print(mini_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mini_fact in mini_facts_test:\n",
    "    if mini_fact in mini_facts_train:\n",
    "        print(mini_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_docs1 = set(all_docs1)\n",
    "set_docs2 = set(all_docs2)\n",
    "\n",
    "# Check if there's any overlap\n",
    "common_docs = set_docs1.intersection(set_docs2)\n",
    "\n",
    "# Print the result\n",
    "if not common_docs:\n",
    "    print(\"No common documents found between df1 and df2.\")\n",
    "else:\n",
    "    print(\"Common documents found:\", common_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import os \n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "model_path = \"/home/wombat_share/llms/llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "device = torch.device(f\"cuda:1\")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "#    #bnb_4bit_use_double_quant=True,\n",
    "#    #bnb_4bit_quant_type=\"nf4\",\n",
    "#    #bnb_4bit_compute_dtype=torch.bfloat16 #if use_flash_attention2 else torch.float16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    #quantization_config=bnb_config,\n",
    "    load_in_4bit=True,\n",
    "    local_files_only=True,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def call_text_llm(new_prompt):\n",
    "    #number_examples = new_prompt.count(\"###\")\n",
    "\n",
    "    #sentinel_token_ids = tokenizer(\"###\", add_special_tokens=False, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "    #stopping_criteria_list = transformers.StoppingCriteriaList([\n",
    "    #    TokenStoppingCriteria(sentinel_token_ids=sentinel_token_ids, starting_idx=0, counter=0, stop_counter=number_examples)\n",
    "    #])\n",
    "\n",
    "\n",
    "    inputs = tokenizer(new_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        #stopping_criteria=stopping_criteria_list,\n",
    "        do_sample=False,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "        temperature=1.0,\n",
    "        top_p=1.0,\n",
    "    )\n",
    "\n",
    "    transition_scores = model.compute_transition_scores(\n",
    "        outputs.sequences, outputs.scores, normalize_logits=True\n",
    "    )\n",
    "\n",
    "    #prompt_length = inputs['input_ids'].shape[1]\n",
    "    #response = outputs[0][prompt_length:]\n",
    "    #new_output = tokenizer.decode(response, skip_special_tokens=False)\n",
    "\n",
    "\n",
    "    #input_length = 1 if model.config.is_encoder_decoder else inputs.shape[1]\n",
    "\n",
    "    input_length = inputs.input_ids.shape[1]\n",
    "    \n",
    "    generated_tokens = outputs.sequences[:, input_length:]\n",
    "    data = []\n",
    "    for tok, score in zip(generated_tokens[0], transition_scores[0]):\n",
    "        # | token | token string | logits | probability\n",
    "        #print(f\"| {tok:5d} | {tokenizer.decode(tok):8s} | {score.cpu().numpy():.4f} | {np.exp(score.cpu().numpy()):.2%}\")\n",
    "        #print(f\"{self.tokenizer.decode(tok):8s} | {np.exp(score_cpu)}\")\n",
    "        data.append([tokenizer.decode(tok), np.exp(score.cpu().numpy())])\n",
    "\n",
    "    return tokenizer.decode(generated_tokens[0], skip_special_tokens=True), data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def call_message_llm(messages):\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    terminators = [\n",
    "        tokenizer.eos_token_id,\n",
    "        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "    ]\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=256,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=False,\n",
    "        #output_hidden_states=True,\n",
    "        #return_dict_in_generate=with_probs,\n",
    "        #output_scores=with_probs,\n",
    "        temperature=1.0,\n",
    "        top_p=1.0,\n",
    "    )\n",
    "\n",
    "    response = outputs[0][input_ids.shape[-1]:]\n",
    "    return tokenizer.decode(response, skip_special_tokens=True)\n",
    "\n",
    "text_prompt = \"\"\" Please breakdown the following sentence into independent facts: He made his acting debut in the film The Moon is the Sun’s Dream (1992), and continued to\n",
    " appear in small and supporting roles throughout the 1990s. - He made his acting debut in the film. - He made his acting debut in The Moon is the Sun’s Dream. - The Moon is the Sun’s Dream is a film. - The Moon is the Sun’s Dream was released in 1992. - After his acting debut, he appeared in small and supporting roles. - After his acting debut, he appeared in small and supporting roles throughout the 1990s.\n",
    " Please breakdown the following sentence into independent facts: He is also a successful producer and engineer, having worked with a wide variety of artists,\n",
    " including Willie Nelson, Tim McGraw, and Taylor Swift. - He is successful. -He is aproducer. -He is a engineer. -He has worked with a wide variety of artists. - Willie Nelson is an artist. - He has worked with Willie Nelson. -Tim McGraw is an artist. - He has worked with Tim McGraw. - Taylor Swift is an artist. - He has worked with Taylor Swift.\n",
    " Please breakdown the following sentence into independent facts: In 1963, Collins became one of the third group of astronauts selected by NASA and he served\n",
    " as the back-up Command Module Pilot for the Gemini 7 mission. - Collins became an astronaut. - Collins became one of the third group of astronauts.- Collins became one of the third group of astronauts selected. - Collins became one of the third group of astronauts selected by NASA. - Collins became one of the third group of astronauts selected by NASA in 1963. - He served as the Command Module Pilot. - He served as the back-up Command Module Pilot. - He served as the Command Module Pilot for the Gemini 7 mission.\n",
    " Please breakdown the following sentence into independent facts: In addition to his acting roles, Bateman has written and directed two short films and is\n",
    " currently in development on his feature debut.- Bateman has acting roles. - Bateman has written two short films. - Bateman has directed two short films. - Bateman has written and directed two short films. - Bateman is currently in development on his feature debut.\n",
    " Please breakdown the following sentence into independent facts: Michael Collins (born October 31, 1930) is a retired American astronaut and test pilot who\n",
    " was the Command Module Pilot for the Apollo 11 mission in 1969. - Michael Collins was born on October 31, 1930. - Michael Collins is retired. - Michael Collins is an American. - Michael Collins was an astronaut. - Michael Collins was a test pilot. - Michael Collins was the Command Module Pilot. - Michael Collins was the Command Module Pilot for the Apollo 11 mission. - Michael Collins was the Command Module Pilot for the Apollo 11 mission in 1969.\n",
    " Please breakdown the following sentence into independent facts: He was an American composer, conductor, and musical director.- He was an American. - He was a composer. - He was a conductor. -He was a musical director.\n",
    " Please breakdown the following sentence into independent facts: She currently stars in the romantic comedy series, Love and Destiny, which premiered in 2019. - She currently stars in Love and Destiny. - Love and Destiny is a romantic comedy series. - Love and Destiny premiered in 2019.\n",
    " Please breakdown the following sentence into independent facts: During his professional career, McCoy played for the Broncos, the San Diego Chargers, the\n",
    " Minnesota Vikings, and the Jacksonville Jaguars. - McCoy played for the Broncos. - McCoy played for the Broncos during his professional career. - McCoy played for the San Diego Chargers. - McCoy played for the San Diego Chargers during his professional career. - McCoyplayed for the Minnesota Vikings. - McCoy played for the Minnesota Vikings during his professional career. - Mc Coy played for the Jacksonville Jaguars. - McCo yplayed for the Jacksonville Jaguars during his professional career. Please breakdown the following sentence into independent facts:\"\"\"\n",
    "\n",
    "\n",
    "instruct_atomic_facts_prompt = \"\"\"Please breakdown the following sentence into independent facts:\"\"\"\n",
    "samples = [\"He made his acting debut in the film The Moon is the Sun’s Dream (1992), and continued to appear in small and supporting roles throughout the 1990s.\", \n",
    "           \"He is also a successful producer and engineer, having worked with a wide variety of artists, including Willie Nelson, Tim McGraw, and Taylor Swift.\",\n",
    "           \"Michael Collins (born October 31, 1930) is a retired American astronaut and test pilot who was the Command Module Pilot for the Apollo 11 mission in 1969.\",\n",
    "           \"He was an American composer, conductor, and musical director.\", \n",
    "           \"She currently stars in the romantic comedy series, Love and Destiny, which premiered in 2019.\",\n",
    "           \"During his professional career, McCoy played for the Broncos, the San Diego Chargers, the Minnesota Vikings, and the Jacksonville Jaguars.\"\n",
    "           ]\n",
    "\n",
    "sample_atomic_facts = [\"\"\"- He made his acting debut in The Moon is the Sun’s Dream. - The Moon is the Sun’s Dream is a film. - The Moon is the Sun’s Dream was released in 1992. - After his acting debut, he appeared in small and supporting roles. - After his acting debut, he appeared in small and supporting roles throughout the 1990s.\"\"\",\n",
    "\"\"\"- He is successful. -He is aproducer. -He is a engineer. -He has worked with a wide variety of artists. - Willie Nelson is an artist. - He has worked with Willie Nelson. -Tim McGraw is an artist. - He has worked with Tim McGraw. - Taylor Swift is an artist. - He has worked with Taylor Swift.\"\"\",\n",
    "\"\"\"- Collins became an astronaut. - Collins became one of the third group of astronauts.- Collins became one of the third group of astronauts selected. - Collins became one of the third group of astronauts selected by NASA. - Collins became one of the third group of astronauts selected by NASA in 1963. - He served as the Command Module Pilot. - He served as the back-up Command Module Pilot. - He served as the Command Module Pilot for the Gemini 7 mission.\"\"\",\n",
    "\"\"\"- He was an American. - He was a composer. - He was a conductor. -He was a musical director.\"\"\",\n",
    "\"\"\"- She currently stars in Love and Destiny. - Love and Destiny is a romantic comedy series. - Love and Destiny premiered in 2019.\"\"\",\n",
    "\"\"\"- McCoy played for the Broncos. - McCoy played for the Broncos during his professional career. - McCoy played for the San Diego Chargers. - McCoy played for the San Diego Chargers during his professional career. - McCoyplayed for the Minnesota Vikings. - McCoy played for the Minnesota Vikings during his professional career. - Mc Coy played for the Jacksonville Jaguars. - McCo yplayed for the Jacksonville Jaguars during his professional career.\"\"\"\n",
    "]\n",
    "\n",
    "#text_prompt = text_prompt + \"Stranger Than Fiction is a 2006 American fantasy comedy-drama film directed by Spike Jonze and written by Charlie Kaufman.\"\n",
    "\n",
    "\n",
    "def get_messages(sample):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instruct_atomic_facts_prompt},\n",
    "        {\"role\": \"user\", \"content\": samples[0]},\n",
    "        {\"role\": \"assistant\", \"content\": sample_atomic_facts[0]},\n",
    "        #{\"role\": \"system\", \"content\": instruct_atomic_facts_prompt},\n",
    "        {\"role\": \"user\", \"content\": samples[1]},\n",
    "        {\"role\": \"assistant\", \"content\": sample_atomic_facts[1]},\n",
    "        #{\"role\": \"system\", \"content\": instruct_atomic_facts_prompt},\n",
    "        {\"role\": \"user\", \"content\": samples[2]},\n",
    "        {\"role\": \"assistant\", \"content\": sample_atomic_facts[2]},\n",
    "        #{\"role\": \"system\", \"content\": instruct_atomic_facts_prompt},\n",
    "        {\"role\": \"user\", \"content\": samples[3]},\n",
    "        {\"role\": \"assistant\", \"content\": sample_atomic_facts[3]},\n",
    "        #{\"role\": \"system\", \"content\": instruct_atomic_facts_prompt},\n",
    "        {\"role\": \"user\", \"content\": samples[4]},\n",
    "        {\"role\": \"assistant\", \"content\": sample_atomic_facts[4]},\n",
    "        #{\"role\": \"system\", \"content\": instruct_atomic_facts_prompt},\n",
    "        {\"role\": \"user\", \"content\": samples[5]},\n",
    "        {\"role\": \"assistant\", \"content\": sample_atomic_facts[5]},\n",
    "        #{\"role\": \"system\", \"content\": instruct_atomic_facts_prompt},\n",
    "\n",
    "    ]\n",
    "    messages.append({\"role\": \"user\", \"content\": sample})\n",
    "    return messages\n",
    "\n",
    "\n",
    "test_samples = [\"Stranger Than Fiction is a 2006 American fantasy comedy-drama film directed by Spike Jonze and written by Charlie Kaufman.\", \n",
    "                \"The Peloponnesian War was a devastating conflict between Athens and Sparta, which lasted from 431 to 404 BCE. The war was won by Athens, not Sparta.\",\n",
    "                \"Ronald Reagan was the 40th President of the United States, serving from 1981 to 1989\",\n",
    "                \"Debbie Reynolds starred in the 1989 revival of Irene, not 1994.\"]\n",
    "\n",
    "for test in test_samples:\n",
    "    messages = get_messages(test)\n",
    "    #new_prompt = text_prompt + test\n",
    "    output = call_message_llm(messages)\n",
    "    print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
