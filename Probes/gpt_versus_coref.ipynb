{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be used to generate/evaluate coreference resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# for example load evidences\n",
    "df_sentences = pd.read_csv(\"datasets_hover_llama/mini_fact_hover.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from fastcoref import spacy_component\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp.add_pipe(\n",
    "    \"fastcoref\", \n",
    "    config={\n",
    "        'model_architecture': 'LingMessCoref', \n",
    "        'model_path': 'biu-nlp/lingmess-coref', \n",
    "        'device': 'cuda' \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_sentences(text):\n",
    "    all_sentences = []\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    all_sentences.append(sentences)\n",
    "    all_sentences = [item for sublist in all_sentences for item in sublist]\n",
    "    return all_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcoref import spacy_component\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\n",
    "   \"fastcoref\", \n",
    "   config={'model_architecture': 'LingMessCoref', 'model_path': 'biu-nlp/lingmess-coref', 'device': 'cuda'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "coref_samples = []\n",
    "raw_samples = []\n",
    "gpt_samples = []\n",
    "\n",
    "df_evidence = df_sentences.groupby('gen_evidence')\n",
    "evidence_groups = list(df_evidence)\n",
    "rng = random.Random(42)\n",
    "\n",
    "\n",
    "rng.shuffle(evidence_groups)\n",
    "\n",
    "for gen_evidence, group in evidence_groups:\n",
    "    gen_evidence_with_coref = group['gen_evidence_with_coref'].values[0]\n",
    "    gen_evidence_sentences = convert_text_to_sentences(gen_evidence)\n",
    "    \n",
    "    if str(gen_evidence_with_coref).strip() != str(gen_evidence).strip():\n",
    "        if len(gen_evidence_sentences) > 1:\n",
    "            print(gen_evidence)\n",
    "            print(gen_evidence_with_coref)\n",
    "            \n",
    "            doc = nlp(      \n",
    "                gen_evidence, \n",
    "                component_cfg={\"fastcoref\": {'resolve_text': True}}\n",
    "            )\n",
    "\n",
    "            resolved_text = doc._.resolved_text\n",
    "            print(resolved_text)\n",
    "            \n",
    "            raw_samples.append(gen_evidence)\n",
    "            coref_samples.append(resolved_text)\n",
    "            gpt_samples.append(gen_evidence_with_coref)\n",
    "\n",
    "            if len(coref_samples) == 100:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'Raw Sample': raw_samples,\n",
    "    'Coref Edit': coref_samples,\n",
    "    'GPT Edit': gpt_samples,\n",
    "})\n",
    "\n",
    "df.to_excel('gpt_coref.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_excel('gpt_coref.xlsx')\n",
    "\n",
    "df = df.loc[(df['Correct Coref'] != 2) & (df['Correct GPT'] != 2)].iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "488\n",
      "0.976\n",
      "103\n",
      "0.206\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_excel('gpt_coref.xlsx')\n",
    "\n",
    "#df2 = df.loc[(df['Correct GPT'] == 2)]\n",
    "#print(len(df2))\n",
    "\n",
    "#df = df.loc[(df['Correct Coref'] != 2) & (df['Correct GPT'] != 2)]\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "df_gpt = df.loc[(df['Correct GPT'] == 1) | (df['Correct GPT'] == 2)]\n",
    "df_coref = df.loc[(df['Correct Coref'] == 1) ]\n",
    "\n",
    "print(len(df_gpt))\n",
    "print(len(df_gpt) / len(df))\n",
    "\n",
    "print(len(df_coref))\n",
    "print(len(df_coref) / len(df))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
