{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1355\n",
      "1543\n",
      "\\begin{table}[h]\n",
      "\\centering\n",
      "\\small\n",
      "\\begin{tabular}{p{1.5cm} | p{4.5cm}| p{1.5cm} | p{1.5cm} | p{1.5cm} | p{1.5cm}}\n",
      "\\toprule\n",
      "Test Set & Metric & GPT-4o-mini & Llama-70B-Instruct & Llama-8B-Instruct & Llama-8B-Instruct-\\textbf{Finetuning} \\\\\n",
      "\\midrule\n",
      "\\addlinespace[10pt]\n",
      "\\multirow{4}{*}{\\vspace{-8pt}\\parbox{2cm}{FEVER: \\\\ 1355 \\\\ samples}}\n",
      "& LLM-generated Removals & 521 & 542 & 866 & 606 \\\\\n",
      "& LLM-generated Corrections & \\textbf{821} & 763 & 429 & 742 \\\\\n",
      "& True Corrected Facts & 648 & 631 & 170 & 657 \\\\\n",
      "& Correction Rate & 0.789 & 0.827 & 0.396 & \\textbf{0.885} \\\\\n",
      "\\addlinespace[10pt]\n",
      "\\midrule\n",
      "\\addlinespace[10pt]\n",
      "\\multirow{4}{*}{\\vspace{-10pt}\\parbox{2cm}{HoVer: \\\\ 1543 \\\\ samples}}\n",
      "& LLM-generated Removals & 621 & 604 & 1127 & 660 \\\\\n",
      "& LLM-generated Corrections & \\textbf{910} & 891 & 354 & 867 \\\\\n",
      "& True Corrected Facts & 697 & 734 & 110 & 724 \\\\\n",
      "& Correction Rate & 0.766 & 0.824 & 0.311 & \\textbf{0.835} \\\\\n",
      "\\addlinespace[10pt]\\bottomrule\n",
      "\\end{tabular}\n",
      "\\caption{Comparison of LLM-generated Corrections across LLMs for FEVER and HoVer test sets}\n",
      "\\label{tab:correction_comparison}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in the CSV file\n",
    "df = pd.read_csv(\"evaluation_results.csv\")\n",
    "\n",
    "# Rename columns\n",
    "df.rename(columns={'Corrected Facts': 'LLM-generated Corrections', 'Removed Facts': 'LLM-generated Removals', 'Score Corrected': 'Correction Rate'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Mapping for LLM names\n",
    "llm_mapping = {\n",
    "    'llama': 'Llama-8B-Instruct',\n",
    "    'llama_70B': 'Llama-70B-Instruct',\n",
    "    'openai': 'GPT-4o-mini',\n",
    "    'llama_finetuned': 'Llama-8B-Instruct-\\\\textbf{Finetuning}'\n",
    "}\n",
    "df['LLM'] = df['LLM'].map(llm_mapping)\n",
    "\n",
    "# Pivot the DataFrame\n",
    "pivot_df = df.melt(id_vars=['Dataset', 'LLM'], var_name='Metric', value_name='Value')\n",
    "pivot_df = pivot_df.pivot_table(index=['Dataset', 'Metric'], columns='LLM', values='Value')\n",
    "\n",
    "# Generate LaTeX table from the pivoted DataFrame with bold max values\n",
    "def generate_latex_table(pivot_df):\n",
    "    llms = pivot_df.columns  # Get unique LLM names for columns\n",
    "    latex_table = \"\\\\begin{table}[h]\\n\" \\\n",
    "                  \"\\\\centering\\n\" \\\n",
    "                  \"\\\\small\\n\" \\\n",
    "                  \"\\\\begin{tabular}{p{1.5cm} | p{4.5cm}| \" + \" | \".join(['p{1.5cm}' for _ in llms]) + \"}\\n\" \\\n",
    "                  \"\\\\toprule\\n\" \\\n",
    "                  \"Test Set & Metric & \" + \" & \".join([f'{llm}' for llm in llms]) + \" \\\\\\\\\\n\" \\\n",
    "                  \"\\\\midrule\\n\" \\\n",
    "                  \"\\\\addlinespace[10pt]\\n\"\n",
    "\n",
    "    for dataset in pivot_df.index.levels[0]:  # Loop through datasets (fever and hover)\n",
    "        dataset_name = 'FEVER' if dataset == 'fever' else 'HoVer'\n",
    "        len_facts = int(pivot_df.loc[(dataset, \"Facts\")].values[0])\n",
    "        print(len_facts)\n",
    "        if dataset == 'fever':\n",
    "            latex_table += f\"\\\\multirow{{4}}{{*}}{{\\\\vspace{{-8pt}}\\\\parbox{{2cm}}{{{dataset_name}: \\\\\\ {len_facts} \\\\\\ samples}}}}\\n\"\n",
    "        else:\n",
    "            latex_table += \"\\\\addlinespace[10pt]\\n\"\n",
    "            latex_table += f\"\\\\multirow{{4}}{{*}}{{\\\\vspace{{-10pt}}\\\\parbox{{2cm}}{{{dataset_name}: \\\\\\ {len_facts} \\\\\\ samples}}}}\\n\"\n",
    "        \n",
    "        for idx, metric in enumerate(['LLM-generated Removals', 'LLM-generated Corrections', 'True Corrected Facts', 'Correction Rate']):\n",
    "            if idx == 0:\n",
    "                latex_table += f\"& {metric} & \"\n",
    "            else:\n",
    "                latex_table += f\"& {metric} & \"\n",
    "\n",
    "            # Determine the maximum value in the row for bolding (only for specific metrics)\n",
    "            if metric in ['LLM-generated Corrections', 'Correction Rate']:\n",
    "                max_value = pivot_df.loc[(dataset, metric)].max()\n",
    "\n",
    "            metric_values = []\n",
    "            for llm in llms:\n",
    "                value = pivot_df.loc[(dataset, metric), llm]\n",
    "                if pd.notna(value):\n",
    "                    if metric in ['LLM-generated Removals', 'LLM-generated Corrections', 'True Corrected Facts']:\n",
    "                        formatted_value = f\"{value:.0f}\"  # Integer format\n",
    "                    else:\n",
    "                        formatted_value = f\"{value:.3f}\"  # Float format for \"Correction Rate\"\n",
    "\n",
    "                    # Apply bold formatting only if the value is the maximum and metric is not 'LLM-generated Removals'\n",
    "                    if metric in ['LLM-generated Corrections', 'Correction Rate'] and np.isclose(value, max_value):\n",
    "                        formatted_value = f\"\\\\textbf{{{formatted_value}}}\"\n",
    "                    \n",
    "                    metric_values.append(formatted_value)\n",
    "                else:\n",
    "                    metric_values.append('-')\n",
    "\n",
    "            latex_table += \" & \".join(metric_values) + \" \\\\\\\\\\n\"\n",
    "            #latex_table += \"\\\\addlinespace[5pt]\\n\"\n",
    "\n",
    "        latex_table += \"\\\\addlinespace[10pt]\\n\"\n",
    "        latex_table += \"\\\\midrule\\n\"\n",
    "\n",
    "    latex_table = latex_table.rstrip(\"\\\\midrule\\n\")  # Remove the last midrule\n",
    "    latex_table += \"\\\\bottomrule\\n\" \\\n",
    "                   \"\\\\end{tabular}\\n\" \\\n",
    "                   \"\\\\caption{Comparison of LLM-generated Corrections across LLMs for FEVER and HoVer test sets}\\n\" \\\n",
    "                   \"\\\\label{tab:correction_comparison}\\n\" \\\n",
    "                   \"\\\\end{table}\"\n",
    "\n",
    "    return latex_table\n",
    "\n",
    "# Print the generated LaTeX table\n",
    "latex_table = generate_latex_table(pivot_df)\n",
    "print(latex_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LLM</th>\n",
       "      <th>GPT-4o-mini</th>\n",
       "      <th>Llama-70B-Instruct</th>\n",
       "      <th>Llama-8B-Instruct</th>\n",
       "      <th>Llama-8B-Instruct-\\textbf{Finetuning}</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">fever</th>\n",
       "      <th>Correction Rate</th>\n",
       "      <td>0.789281</td>\n",
       "      <td>0.826999</td>\n",
       "      <td>0.396270</td>\n",
       "      <td>0.885445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Facts</th>\n",
       "      <td>1355.000000</td>\n",
       "      <td>1355.000000</td>\n",
       "      <td>1355.000000</td>\n",
       "      <td>1355.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLM-generated Corrections</th>\n",
       "      <td>821.000000</td>\n",
       "      <td>763.000000</td>\n",
       "      <td>429.000000</td>\n",
       "      <td>742.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLM-generated Removals</th>\n",
       "      <td>521.000000</td>\n",
       "      <td>542.000000</td>\n",
       "      <td>866.000000</td>\n",
       "      <td>606.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score Removed</th>\n",
       "      <td>0.953935</td>\n",
       "      <td>0.948339</td>\n",
       "      <td>0.967667</td>\n",
       "      <td>0.945545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Score</th>\n",
       "      <td>0.845018</td>\n",
       "      <td>0.845018</td>\n",
       "      <td>0.743911</td>\n",
       "      <td>0.907749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Corrected Facts</th>\n",
       "      <td>648.000000</td>\n",
       "      <td>631.000000</td>\n",
       "      <td>170.000000</td>\n",
       "      <td>657.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Removed Facts</th>\n",
       "      <td>497.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>838.000000</td>\n",
       "      <td>573.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">hover</th>\n",
       "      <th>Correction Rate</th>\n",
       "      <td>0.765934</td>\n",
       "      <td>0.823793</td>\n",
       "      <td>0.310734</td>\n",
       "      <td>0.835063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Facts</th>\n",
       "      <td>1543.000000</td>\n",
       "      <td>1543.000000</td>\n",
       "      <td>1543.000000</td>\n",
       "      <td>1543.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLM-generated Corrections</th>\n",
       "      <td>910.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>867.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LLM-generated Removals</th>\n",
       "      <td>621.000000</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>1127.000000</td>\n",
       "      <td>660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Score Removed</th>\n",
       "      <td>0.993559</td>\n",
       "      <td>0.993377</td>\n",
       "      <td>0.995563</td>\n",
       "      <td>0.993939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Score</th>\n",
       "      <td>0.851588</td>\n",
       "      <td>0.864550</td>\n",
       "      <td>0.798445</td>\n",
       "      <td>0.894362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Corrected Facts</th>\n",
       "      <td>697.000000</td>\n",
       "      <td>734.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>724.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Removed Facts</th>\n",
       "      <td>617.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>1122.000000</td>\n",
       "      <td>656.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "LLM                                GPT-4o-mini  Llama-70B-Instruct  \\\n",
       "Dataset Metric                                                       \n",
       "fever   Correction Rate               0.789281            0.826999   \n",
       "        Facts                      1355.000000         1355.000000   \n",
       "        LLM-generated Corrections   821.000000          763.000000   \n",
       "        LLM-generated Removals      521.000000          542.000000   \n",
       "        Score Removed                 0.953935            0.948339   \n",
       "        Total Score                   0.845018            0.845018   \n",
       "        True Corrected Facts        648.000000          631.000000   \n",
       "        True Removed Facts          497.000000          514.000000   \n",
       "        Unnamed: 0                    2.000000            0.000000   \n",
       "hover   Correction Rate               0.765934            0.823793   \n",
       "        Facts                      1543.000000         1543.000000   \n",
       "        LLM-generated Corrections   910.000000          891.000000   \n",
       "        LLM-generated Removals      621.000000          604.000000   \n",
       "        Score Removed                 0.993559            0.993377   \n",
       "        Total Score                   0.851588            0.864550   \n",
       "        True Corrected Facts        697.000000          734.000000   \n",
       "        True Removed Facts          617.000000          600.000000   \n",
       "        Unnamed: 0                    6.000000            4.000000   \n",
       "\n",
       "LLM                                Llama-8B-Instruct  \\\n",
       "Dataset Metric                                         \n",
       "fever   Correction Rate                     0.396270   \n",
       "        Facts                            1355.000000   \n",
       "        LLM-generated Corrections         429.000000   \n",
       "        LLM-generated Removals            866.000000   \n",
       "        Score Removed                       0.967667   \n",
       "        Total Score                         0.743911   \n",
       "        True Corrected Facts              170.000000   \n",
       "        True Removed Facts                838.000000   \n",
       "        Unnamed: 0                          3.000000   \n",
       "hover   Correction Rate                     0.310734   \n",
       "        Facts                            1543.000000   \n",
       "        LLM-generated Corrections         354.000000   \n",
       "        LLM-generated Removals           1127.000000   \n",
       "        Score Removed                       0.995563   \n",
       "        Total Score                         0.798445   \n",
       "        True Corrected Facts              110.000000   \n",
       "        True Removed Facts               1122.000000   \n",
       "        Unnamed: 0                          7.000000   \n",
       "\n",
       "LLM                                Llama-8B-Instruct-\\textbf{Finetuning}  \n",
       "Dataset Metric                                                            \n",
       "fever   Correction Rate                                         0.885445  \n",
       "        Facts                                                1355.000000  \n",
       "        LLM-generated Corrections                             742.000000  \n",
       "        LLM-generated Removals                                606.000000  \n",
       "        Score Removed                                           0.945545  \n",
       "        Total Score                                             0.907749  \n",
       "        True Corrected Facts                                  657.000000  \n",
       "        True Removed Facts                                    573.000000  \n",
       "        Unnamed: 0                                              1.000000  \n",
       "hover   Correction Rate                                         0.835063  \n",
       "        Facts                                                1543.000000  \n",
       "        LLM-generated Corrections                             867.000000  \n",
       "        LLM-generated Removals                                660.000000  \n",
       "        Score Removed                                           0.993939  \n",
       "        Total Score                                             0.894362  \n",
       "        True Corrected Facts                                  724.000000  \n",
       "        True Removed Facts                                    656.000000  \n",
       "        Unnamed: 0                                              5.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
