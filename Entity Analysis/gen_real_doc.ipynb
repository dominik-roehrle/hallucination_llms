{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_wikipedia_pageviews(article_title, start_date='20230101', end_date='20231231'):\n",
    "    url = f\"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/en.wikipedia/all-access/user/{article_title}/daily/{start_date}/{end_date}\"\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'WikiPageviewsAnalyzer/1.0' \n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "\n",
    "        if 'items' in data: \n",
    "            total_views = sum([item['views'] for item in data['items']])\n",
    "            return total_views\n",
    "        else:\n",
    "            print(f\"No 'items' found for {article_title}\")\n",
    "            return 0\n",
    "    else:\n",
    "        print(f\"Error fetching data for {article_title}, status code: {response.status_code}\")\n",
    "        return 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "def calculate_total_popularity_and_closest_article(docs, output_mini_fact):\n",
    "    cosine_scores = []\n",
    "    print(docs)\n",
    "\n",
    "    for doc in docs:\n",
    "        tfidf_matrix = vectorizer.fit_transform([output_mini_fact, doc])\n",
    "        cosine_score = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0, 0]  \n",
    "        cosine_scores.append(cosine_score)\n",
    "\n",
    "    closest_article = docs[cosine_scores.index(max(cosine_scores))]\n",
    "    pageviews = get_wikipedia_pageviews(closest_article) \n",
    "    return pageviews, closest_article\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Popularity Column for Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('train/train.pkl')\n",
    "\n",
    "\n",
    "df[['popularity', 'closest_article']] = df.apply(\n",
    "    lambda row: calculate_total_popularity_and_closest_article(row['docs'], row['output_mini_fact']),\n",
    "    axis=1,\n",
    "    result_type='expand'  \n",
    ")\n",
    "\n",
    "df.to_pickle('train/train_with_popularity_unbalanced.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Popularity Column for Test/Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('train/dev.pkl')\n",
    "\n",
    "df[['popularity', 'closest_article']] = df.apply(\n",
    "    lambda row: calculate_total_popularity_and_closest_article(row['docs'], row['output_mini_fact']),\n",
    "    axis=1,\n",
    "    result_type='expand'  \n",
    ")\n",
    "\n",
    "df.to_pickle('train/dev_with_popularity_unbalanced.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get real samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata2\n",
    "import sqlite3\n",
    "\n",
    "def query_wiki(doc_title):\n",
    "    conn = sqlite3.connect('wiki_wo_links.db')\n",
    "    c = conn.cursor()\n",
    "\n",
    "    para = (\n",
    "        c.execute(\"SELECT text FROM documents WHERE id = ?\", (unicodedata2.normalize('NFD', doc_title),)).fetchall()\n",
    "    )[0][0]\n",
    "\n",
    "    conn.close()\n",
    "    return para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_facts_instruction = f\"\"\"Your task is to breakdown claims/sentences into independant and verifiable statements (maximum 4). \n",
    "You must NEVER correct or comment the original claims/sentences even if something of the original claims/sentences is incorrect.\n",
    "Do NEVER generate statements that are not in the original claims/sentences. Every statement must start with an entity that specifies the topic (e.g. **The Fox Broadcasting Company** and not **The company**).\"\"\"\n",
    "        \n",
    "mini_facts_samples = [\"The Hunger Games is a 2012 American science fiction film directed by John Peter and based on the novel of the same name by Suzanne Collins. Matt Lucena is an American former professional tennis player.\",\n",
    "\"\"\"Owen Wilson starred in the film \"The Karate Kid\" (2010) alongside martial arts expert Tom Wu. Owen Wilson voiced Lightning McQueen in the \"Cars\" franchise, not \"The Royal Tenenbaums\" franchise.\"\"\",\n",
    "\"Feels So Good is a song by the American R&B group Tony! Toni! TonÃ. The song was written by the group's lead vocalist Raphael Saadiq and producer Tony! Toni! TonÃ's lead vocalist Dwayne Wimberly.\"]\n",
    "        \n",
    "        \n",
    "mini_facts_sample_outputs = [\"\"\"- **The Hunger Games** is a 2012 American science fiction film.\n",
    "- **The Hunger Games** was directed by John Peter.\n",
    "- **The Hunger Games** is based on a novel of the same name by Suzanne Collins.\n",
    "- **Matt Lucena** is an American former professional tennis player.\"\"\",\n",
    "\"\"\"- **Owen Wilson** starred in the film The Karate Kid (2010) alongside martial arts expert Tom Wu.\n",
    "- **Owen Wilson** voiced Lightning McQueen in the Cars franchise.\n",
    "- **Owen Wilson** did not voice Lightning McQueen in the The Royal Tenenbaums franchise.\"\"\",\n",
    "\"\"\"- **Feels So Good** is a song by the American R&B group Tony! Toni! TonÃ.\n",
    "- **Feels So Good** was written by the group's lead vocalist Raphael Saadiq and producer Tony! Toni! TonÃ's lead vocalist Dwayne Wimberly.\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import torch\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "with open(\"../api.key\", \"r\") as file:\n",
    "    api_key = file.read().strip() \n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def convert_text_to_sentences(text):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    return sentences\n",
    "\n",
    "def call_llm(messages, response_format):\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        max_tokens=256,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        response_format={\n",
    "            \"type\": response_format\n",
    "        }\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "    \n",
    "\n",
    "def get_prompt_mini_facts(gen_evidence):\n",
    "    messages = [{\"role\": \"system\", \n",
    "            \"content\" : [{\"type\": \"text\", \n",
    "                        \"text\": f\"{mini_facts_instruction}\"}]},\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": f\"{mini_facts_samples[0]}\"}]},\n",
    "        {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": f\"{mini_facts_sample_outputs[0]}\"}]},\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": f\"{mini_facts_samples[1]}\"}]},\n",
    "        {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": f\"{mini_facts_sample_outputs[1]}\"}]},\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": f\"{mini_facts_samples[2]}\"}]},\n",
    "        {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": f\"{mini_facts_sample_outputs[2]}\"}]},\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": f\"{gen_evidence}\"}]}]\n",
    "    return messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add 150 real Documents (Each Document has 3-4 mini-facts) to each bin of the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_test = pd.read_pickle('test/test_llm_generations.pkl')\n",
    "\n",
    "# Define labels and create quantile-based bins using qcut\n",
    "labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
    "df_test['popularity_bin'] = pd.qcut(df_test['popularity'], q=5, labels=labels)\n",
    "\n",
    "# Initialize an empty DataFrame to store results\n",
    "df_real_test_samples = pd.DataFrame()\n",
    "\n",
    "# Iterate over each bin group\n",
    "for bin_label, bin_group in df_test.groupby('popularity_bin'):\n",
    "    count_in_bin = 0\n",
    "    \n",
    "    # Process each row within the bin\n",
    "    for index, row in bin_group.iterrows():\n",
    "        popularity = row['popularity']\n",
    "        closest_article = row['closest_article']\n",
    "        \n",
    "        # Query wiki, convert to sentences, and generate prompt\n",
    "        text = query_wiki(closest_article)\n",
    "        sentences = convert_text_to_sentences(text)\n",
    "        messages = get_prompt_mini_facts(sentences[0])\n",
    "        output = call_llm(messages, \"text\")\n",
    "        \n",
    "        # Process the LLM response\n",
    "        response = output.replace(\"**\", \"\").replace(\"-\", \"\")\n",
    "        response = response.split(\"\\n\")\n",
    "        response = [item.strip() for item in response if item.strip()]\n",
    "        \n",
    "        # Append each mini fact to df_new\n",
    "        for mini_fact in response:\n",
    "            df_real_samples = pd.concat([df_real_test_samples, pd.DataFrame({\n",
    "                'output_mini_fact': [mini_fact],\n",
    "                'label_mini_fact': [1],\n",
    "                'closest_article': [[closest_article]],\n",
    "                'popularity': [popularity]\n",
    "            })], ignore_index=True)\n",
    "        \n",
    "        count_in_bin += 1\n",
    "        # Stop after processing 50 entries for the current bin\n",
    "        if count_in_bin >= 150:\n",
    "            print(f\"Completed {count_in_bin} entries for popularity bin {bin_label}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Completed {count_in_bin} entries for popularity bin {bin_label}\")\n",
    "\n",
    "# Final count for df_real_test_samples\n",
    "print(\"Total entries added:\", len(df_real_test_samples))\n",
    "df_real_test_samples.to_pickle('test_folder/mini_fact_hover_test_with_popularity_real_samples.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add real Train Samples with Low popularity (e.g popularity < 5000 corresponds to documents in bin 'Very Low' and bin 'Low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_train_samples = pd.DataFrame()\n",
    "count_low_popularity = 0\n",
    "\n",
    "df_with_popularity_unbalanced = pd.read_pickle('train/train_with_popularity_unbalanced.pkl')\n",
    "\n",
    "for index, row in df_with_popularity_unbalanced.iterrows():\n",
    "    if index % 100 == 0:\n",
    "        print(count_low_popularity)\n",
    "\n",
    "    if count_low_popularity == 2000:\n",
    "        break\n",
    "    popularity = row['popularity']\n",
    "    if popularity < 5000:\n",
    "        count_low_popularity += 1\n",
    "        closest_article = row['closest_article']\n",
    "        text = query_wiki(closest_article)\n",
    "        sentences = convert_text_to_sentences(text)\n",
    "        messages = get_prompt_mini_facts(sentences[0])\n",
    "        output = call_llm(messages, \"text\")\n",
    "        response = output.replace(\"**\", \"\").replace(\"-\", \"\")\n",
    "        response = response.split(\"\\n\")\n",
    "        response = [item.strip() for item in response]\n",
    "        for mini_fact in response:\n",
    "            df_real_train_samples = pd.concat([df_real_train_samples, pd.DataFrame({'output_mini_fact' : [mini_fact], 'label_mini_fact': [1], 'closest_article' : [[closest_article]], 'popularity' : [popularity]})], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Samples need embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "\n",
    "remove_period = True\n",
    "model_path = \"C:/Users/droeh/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B-Instruct/snapshots/e5e23bbe8e749ef0efcf16cad411a7d23bd23298\"\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True,\n",
    "    local_files_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "def get_embeddings(df_real_samples):\n",
    "    embeddings_name = f\"embeddings-16_mini_fact\"\n",
    "    layer = -16\n",
    "    df_real_samples[str(embeddings_name)] = None\n",
    "    df_real_samples[str(embeddings_name)] = df_real_samples[str(embeddings_name)].astype(object)\n",
    "\n",
    "    def process_row(prompt, layer):\n",
    "        if remove_period:\n",
    "            prompt = prompt.rstrip(\". \")\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(inputs.input_ids, output_hidden_states=True, return_dict_in_generate=True, max_new_tokens=1, min_new_tokens=1)\n",
    "        embeddings = {}\n",
    "        last_hidden_state = outputs.hidden_states[0][layer][0][-1]\n",
    "        last_hidden_state = last_hidden_state.to(torch.float32)\n",
    "        embeddings[layer] = [last_hidden_state.cpu().numpy().tolist()]\n",
    "        return embeddings\n",
    "\n",
    "    for index, row in df_real_samples.iterrows():\n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "        mini_fact = row['output_mini_fact']\n",
    "        embeddings_list = process_row(mini_fact, layer)\n",
    "        df_real_samples.at[index, str(embeddings_name)] = embeddings_list[layer][0]\n",
    "\n",
    "    return df_real_samples\n",
    "\n",
    "df_real_train_samples = get_embeddings(df_real_train_samples)\n",
    "df_real_test_samples = get_embeddings(df_real_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balance all dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_with_popularity_unbalanced = pd.read_pickle('train/train_with_popularity_unbalanced.pkl')\n",
    "df_real_train_samples = pd.read_pickle('train/train_injection_low_popularity_with_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def balance_df_by_popularity(df):\n",
    "\n",
    "    labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
    "    df['popularity_bin'] = pd.qcut(df['popularity'], q=5, labels=labels)\n",
    "\n",
    "\n",
    "    balanced_dfs = []\n",
    "    for bin_label, group in df.groupby('popularity_bin'):\n",
    "        positive_class = group[group['label_mini_fact'] == 1]\n",
    "        negative_class = group[group['label_mini_fact'] == 0]\n",
    "        minority_size = min(len(positive_class), len(negative_class))\n",
    "        print(f\"Balancing bin '{bin_label}' with {minority_size} samples in each class\")\n",
    "        positive_class_balanced = resample(positive_class, replace=False, n_samples=minority_size, random_state=42)\n",
    "        negative_class_balanced = resample(negative_class, replace=False, n_samples=minority_size, random_state=42)\n",
    "        balanced_group = pd.concat([positive_class_balanced, negative_class_balanced])\n",
    "        balanced_dfs.append(balanced_group)\n",
    "\n",
    "    balanced_df = pd.concat(balanced_dfs)\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "df_balanced_with_popularity_balanced_train_injections = pd.concat([df_with_popularity_unbalanced, df_real_train_samples], ignore_index=True)\n",
    "df_balanced_with_popularity_balanced_train_injections = balance_df_by_popularity(df_balanced_with_popularity_balanced_train_injections)\n",
    "\n",
    "#df_balanced_with_popularity_balanced.to_pickle('train/train_with_popularity_balanced.pkl')\n",
    "#df_balanced_with_popularity_balanced_train_injections.to_pickle('train/train_with_popularity_balanced_train_injections.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced_with_popularity_balanced_train_injections"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
