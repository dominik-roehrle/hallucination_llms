{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call the Wikipedia API to get the view counts for document associated with the mini-fact. In HoVer the document with the clostest match is selected (cosine simialrity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_wikipedia_pageviews(article_title, start_date='20230101', end_date='20231231'):\n",
    "    \"\"\" wikipedia pageviews API calling function \"\"\"\n",
    "    \n",
    "    url = f\"https://wikimedia.org/api/rest_v1/metrics/pageviews/per-article/en.wikipedia/all-access/user/{article_title}/daily/{start_date}/{end_date}\"\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': 'WikiPageviewsAnalyzer/1.0' \n",
    "    }\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "\n",
    "        if 'items' in data: \n",
    "            total_views = sum([item['views'] for item in data['items']])\n",
    "            return total_views\n",
    "        else:\n",
    "            print(f\"No 'items' found for {article_title}\")\n",
    "            return 0\n",
    "    else:\n",
    "        print(f\"Error fetching data for {article_title}, status code: {response.status_code}\")\n",
    "        return 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "def calculate_total_popularity_and_closest_article(docs, output_mini_fact):\n",
    "    cosine_scores = []\n",
    "    print(docs)\n",
    "\n",
    "    for doc in docs:\n",
    "        tfidf_matrix = vectorizer.fit_transform([output_mini_fact, doc])\n",
    "        cosine_score = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0, 0]  \n",
    "        cosine_scores.append(cosine_score)\n",
    "\n",
    "    closest_article = docs[cosine_scores.index(max(cosine_scores))]\n",
    "    pageviews = get_wikipedia_pageviews(closest_article) \n",
    "    return pageviews, closest_article\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Popularity Column for Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('train/train.pkl')\n",
    "\n",
    "\n",
    "df[['popularity', 'closest_article']] = df.apply(\n",
    "    lambda row: calculate_total_popularity_and_closest_article(row['docs'], row['output_mini_fact']),\n",
    "    axis=1,\n",
    "    result_type='expand'  \n",
    ")\n",
    "\n",
    "df.to_pickle('train/train_with_popularity_unbalanced.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Popularity Column for Test/Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('train/dev.pkl')\n",
    "\n",
    "df[['popularity', 'closest_article']] = df.apply(\n",
    "    lambda row: calculate_total_popularity_and_closest_article(row['docs'], row['output_mini_fact']),\n",
    "    axis=1,\n",
    "    result_type='expand'  \n",
    ")\n",
    "\n",
    "df.to_pickle('train/dev_with_popularity_unbalanced.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is to get real samples. Since we use mini-facts, every extracted sentence is converted to mini-facts first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata2\n",
    "import sqlite3\n",
    "\n",
    "def query_wiki(doc_title):\n",
    "    conn = sqlite3.connect('../Probes/datasets_llama_hover/wiki_wo_links.db')\n",
    "    c = conn.cursor()\n",
    "\n",
    "    para = (\n",
    "        c.execute(\"SELECT text FROM documents WHERE id = ?\", (unicodedata2.normalize('NFD', doc_title),)).fetchall()\n",
    "    )[0][0]\n",
    "\n",
    "    conn.close()\n",
    "    return para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_facts_instruction = f\"\"\"Your task is to breakdown claims/sentences into independant and verifiable statements (maximum 4). \n",
    "You must NEVER correct or comment the original claims/sentences even if something of the original claims/sentences is incorrect.\n",
    "Do NEVER generate statements that are not in the original claims/sentences. Every statement must start with an entity that specifies the topic (e.g. **The Fox Broadcasting Company** and not **The company**).\"\"\"\n",
    "        \n",
    "mini_facts_samples = [\"The Hunger Games is a 2012 American science fiction film directed by John Peter and based on the novel of the same name by Suzanne Collins. Matt Lucena is an American former professional tennis player.\",\n",
    "\"\"\"Owen Wilson starred in the film \"The Karate Kid\" (2010) alongside martial arts expert Tom Wu. Owen Wilson voiced Lightning McQueen in the \"Cars\" franchise, not \"The Royal Tenenbaums\" franchise.\"\"\",\n",
    "\"Feels So Good is a song by the American R&B group Tony! Toni! TonÃ. The song was written by the group's lead vocalist Raphael Saadiq and producer Tony! Toni! TonÃ's lead vocalist Dwayne Wimberly.\"]\n",
    "        \n",
    "        \n",
    "mini_facts_sample_outputs = [\"\"\"- **The Hunger Games** is a 2012 American science fiction film.\n",
    "- **The Hunger Games** was directed by John Peter.\n",
    "- **The Hunger Games** is based on a novel of the same name by Suzanne Collins.\n",
    "- **Matt Lucena** is an American former professional tennis player.\"\"\",\n",
    "\"\"\"- **Owen Wilson** starred in the film The Karate Kid (2010) alongside martial arts expert Tom Wu.\n",
    "- **Owen Wilson** voiced Lightning McQueen in the Cars franchise.\n",
    "- **Owen Wilson** did not voice Lightning McQueen in the The Royal Tenenbaums franchise.\"\"\",\n",
    "\"\"\"- **Feels So Good** is a song by the American R&B group Tony! Toni! TonÃ.\n",
    "- **Feels So Good** was written by the group's lead vocalist Raphael Saadiq and producer Tony! Toni! TonÃ's lead vocalist Dwayne Wimberly.\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import torch\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "with open(\"../api.key\", \"r\") as file:\n",
    "    api_key = file.read().strip() \n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def convert_text_to_sentences(text):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    return sentences\n",
    "\n",
    "def call_llm(messages, response_format):\n",
    "    client = OpenAI()\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        max_tokens=256,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        response_format={\n",
    "            \"type\": response_format\n",
    "        }\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "    \n",
    "\n",
    "def get_prompt_mini_facts(gen_evidence):\n",
    "    messages = [{\"role\": \"system\", \n",
    "            \"content\" : [{\"type\": \"text\", \n",
    "                        \"text\": f\"{mini_facts_instruction}\"}]},\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": f\"{mini_facts_samples[0]}\"}]},\n",
    "        {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": f\"{mini_facts_sample_outputs[0]}\"}]},\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": f\"{mini_facts_samples[1]}\"}]},\n",
    "        {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": f\"{mini_facts_sample_outputs[1]}\"}]},\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": f\"{mini_facts_samples[2]}\"}]},\n",
    "        {\"role\": \"assistant\", \"content\": [{\"type\": \"text\", \"text\": f\"{mini_facts_sample_outputs[2]}\"}]},\n",
    "        {\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": f\"{gen_evidence}\"}]}]\n",
    "    return messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add 150 real Documents (Each Document has 3-4 mini-facts) to each bin of the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_test = pd.read_pickle('test/test_llm_generations.pkl')\n",
    "\n",
    "labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
    "df_test['popularity_bin'] = pd.qcut(df_test['popularity'], q=5, labels=labels)\n",
    "\n",
    "df_real_test_samples = pd.DataFrame()\n",
    "\n",
    "for bin_label, bin_group in df_test.groupby('popularity_bin'):\n",
    "    count_in_bin = 0\n",
    "    \n",
    "    for index, row in bin_group.iterrows():\n",
    "        popularity = row['popularity']\n",
    "        closest_article = row['closest_article']\n",
    "        \n",
    "        text = query_wiki(closest_article)\n",
    "        sentences = convert_text_to_sentences(text)\n",
    "        messages = get_prompt_mini_facts(sentences[0])\n",
    "        output = call_llm(messages, \"text\")\n",
    "        \n",
    "        response = output.replace(\"**\", \"\").replace(\"-\", \"\")\n",
    "        response = response.split(\"\\n\")\n",
    "        response = [item.strip() for item in response if item.strip()]\n",
    "        \n",
    "        for mini_fact in response:\n",
    "            df_real_samples = pd.concat([df_real_test_samples, pd.DataFrame({\n",
    "                'output_mini_fact': [mini_fact],\n",
    "                'label_mini_fact': [1],\n",
    "                'closest_article': [[closest_article]],\n",
    "                'popularity': [popularity]\n",
    "            })], ignore_index=True)\n",
    "        \n",
    "        count_in_bin += 1\n",
    "        if count_in_bin >= 150:\n",
    "            print(f\"Completed {count_in_bin} entries for popularity bin {bin_label}\")\n",
    "            break\n",
    "\n",
    "    print(f\"Completed {count_in_bin} entries for popularity bin {bin_label}\")\n",
    "\n",
    "print(\"Total entries added:\", len(df_real_test_samples))\n",
    "df_real_test_samples.to_pickle('test_folder/mini_fact_hover_test_with_popularity_real_samples.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add real Train Samples with Low popularity (e.g popularity < 5000 corresponds to documents in bin 'Very Low' and bin 'Low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_real_train_samples = pd.DataFrame()\n",
    "count_low_popularity = 0\n",
    "\n",
    "df_with_popularity_unbalanced = pd.read_pickle('train/train_with_popularity_unbalanced.pkl')\n",
    "\n",
    "for index, row in df_with_popularity_unbalanced.iterrows():\n",
    "    if index % 100 == 0:\n",
    "        print(count_low_popularity)\n",
    "\n",
    "    if count_low_popularity == 2000:\n",
    "        break\n",
    "    popularity = row['popularity']\n",
    "    if popularity < 5000:\n",
    "        count_low_popularity += 1\n",
    "        closest_article = row['closest_article']\n",
    "        text = query_wiki(closest_article)\n",
    "        sentences = convert_text_to_sentences(text)\n",
    "        messages = get_prompt_mini_facts(sentences[0])\n",
    "        output = call_llm(messages, \"text\")\n",
    "        response = output.replace(\"**\", \"\").replace(\"-\", \"\")\n",
    "        response = response.split(\"\\n\")\n",
    "        response = [item.strip() for item in response]\n",
    "        for mini_fact in response:\n",
    "            df_real_train_samples = pd.concat([df_real_train_samples, pd.DataFrame({'output_mini_fact' : [mini_fact], 'label_mini_fact': [1], 'closest_article' : [[closest_article]], 'popularity' : [popularity]})], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real Samples need embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "\n",
    "\n",
    "remove_period = True\n",
    "# insert the path to the model you want to use\n",
    "model_path = \"\"\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_path, local_files_only=True)\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    load_in_4bit=True,\n",
    "    local_files_only=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "def get_embeddings(df_real_samples):\n",
    "    # we use the embeddings of layer 17\n",
    "    embeddings_name = f\"embeddings-16_mini_fact\"\n",
    "    layer = -16\n",
    "    df_real_samples[str(embeddings_name)] = None\n",
    "    df_real_samples[str(embeddings_name)] = df_real_samples[str(embeddings_name)].astype(object)\n",
    "\n",
    "    def process_row(prompt, layer):\n",
    "        if remove_period:\n",
    "            prompt = prompt.rstrip(\". \")\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(inputs.input_ids, output_hidden_states=True, return_dict_in_generate=True, max_new_tokens=1, min_new_tokens=1)\n",
    "        embeddings = {}\n",
    "        last_hidden_state = outputs.hidden_states[0][layer][0][-1]\n",
    "        last_hidden_state = last_hidden_state.to(torch.float32)\n",
    "        embeddings[layer] = [last_hidden_state.cpu().numpy().tolist()]\n",
    "        return embeddings\n",
    "\n",
    "    for index, row in df_real_samples.iterrows():\n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "        mini_fact = row['output_mini_fact']\n",
    "        embeddings_list = process_row(mini_fact, layer)\n",
    "        df_real_samples.at[index, str(embeddings_name)] = embeddings_list[layer][0]\n",
    "\n",
    "    return df_real_samples\n",
    "\n",
    "df_real_train_samples = get_embeddings(df_real_train_samples)\n",
    "df_real_test_samples = get_embeddings(df_real_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the dfs are balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_with_popularity_unbalanced = pd.read_pickle('train/train_with_popularity_unbalanced.pkl')\n",
    "df_real_train_samples = pd.read_pickle('train/train_injection_low_popularity_with_embeddings.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def balance_df_by_popularity(df):\n",
    "\n",
    "    labels = ['Very Low', 'Low', 'Medium', 'High', 'Very High']\n",
    "    df['popularity_bin'] = pd.qcut(df['popularity'], q=5, labels=labels)\n",
    "\n",
    "    balanced_dfs = []\n",
    "    for bin_label, group in df.groupby('popularity_bin'):\n",
    "        positive_class = group[group['label_mini_fact'] == 1]\n",
    "        negative_class = group[group['label_mini_fact'] == 0]\n",
    "        minority_size = min(len(positive_class), len(negative_class))\n",
    "        print(f\"Balancing bin '{bin_label}' with {minority_size} samples in each class\")\n",
    "        positive_class_balanced = resample(positive_class, replace=False, n_samples=minority_size, random_state=42)\n",
    "        negative_class_balanced = resample(negative_class, replace=False, n_samples=minority_size, random_state=42)\n",
    "        balanced_group = pd.concat([positive_class_balanced, negative_class_balanced])\n",
    "        balanced_dfs.append(balanced_group)\n",
    "\n",
    "    balanced_df = pd.concat(balanced_dfs)\n",
    "    return balanced_df\n",
    "\n",
    "df_balanced_with_popularity_balanced_train_injections = pd.concat([df_with_popularity_unbalanced, df_real_train_samples], ignore_index=True)\n",
    "df_balanced_with_popularity_balanced_train_injections = balance_df_by_popularity(df_balanced_with_popularity_balanced_train_injections)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
